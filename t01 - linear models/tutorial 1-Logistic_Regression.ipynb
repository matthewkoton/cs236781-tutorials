{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$\\newcommand{\\mat}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\mattr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\matinv}[1]{\\boldsymbol {#1}^{-1}}\n",
    "\\newcommand{\\vec}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\vectr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\rvar}[1]{\\mathrm {#1}}\n",
    "\\newcommand{\\rvec}[1]{\\boldsymbol{\\mathrm{#1}}}\n",
    "\\newcommand{\\diag}{\\mathop{\\mathrm {diag}}}\n",
    "\\newcommand{\\set}[1]{\\mathbb {#1}}\n",
    "\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n",
    "\\newcommand{\\pderiv}[2]{\\frac{\\partial #1}{\\partial #2}}\n",
    "\\newcommand{\\bb}[1]{\\boldsymbol{#1}}\n",
    "\\newcommand{\\E}[2][]{\\mathbb{E}_{#1}\\left[#2\\right]}\n",
    "\\newcommand{\\given}[]{~\\middle\\vert~}$$\n",
    "\n",
    "# CS236781: Deep Learning\n",
    "# Tutorial 1: Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this tutorial, we will cover:\n",
    "\n",
    "* Basics of supervised learning\n",
    "    - Definitions\n",
    "    - Basics of optimization\n",
    "    - Types of errors\n",
    "* Classic ML example: Binary logistic regression from scratch using numpy (**self study**)\n",
    "* Multiclass logistic regression from scratch with PyTorch and autograd\n",
    "    - Optimization\n",
    "    - Writing training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:05.689208Z",
     "iopub.status.busy": "2022-03-31T05:57:05.688941Z",
     "iopub.status.idle": "2022-03-31T05:57:21.783611Z",
     "shell.execute_reply": "2022-03-31T05:57:21.783281Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:21.785948Z",
     "iopub.status.busy": "2022-03-31T05:57:21.785840Z",
     "iopub.status.idle": "2022-03-31T05:57:21.802646Z",
     "shell.execute_reply": "2022-03-31T05:57:21.802329Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Theory Reminders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The supervised learning framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We have a labeled dataset of $N$ labelled samples: $\\mathcal{S} = \\{ (\\vec{x}^i,y^i) \\}_{i=1}^N$, where\n",
    "- $\\vec{x}^i = \\left(x^i_1, \\dots, x^i_D\\right) \\in \\mathcal{X}$  is a **sample** or **feature vector**.\n",
    "- $y^i \\in \\mathcal{Y}$ is the **label**.\n",
    "- For classification with $C$ classes, $\\mathcal{Y} = \\{0,\\dots,C-1\\}$, so each $y^i$ is a **class label**.\n",
    "- Probabilistic perspective: assume each labeled sample $(\\vec{x}^i,y^i)\\sim\\mathcal{D}$,\n",
    "  i.e. each labeled sample is drawn from a joint distribution $\\mathcal{D}$ over $\\mathcal{X}\\times\\mathcal{Y}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Our **model** is a parametrized set of functions $\\mathcal{H}\\subseteq \\mathcal{Y}^{\\mathcal{X}}$.\n",
    "\n",
    "($\\mathcal{Y}^{\\mathcal{X}}$ is the set of all functions from $\\mathcal{X}$ to $\\mathcal{Y}$).\n",
    "\n",
    "From a probabilistic perspective, a model is a posterior: $P_{Y|\\vec{X}}(y, \\vec{x})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example, the following hypothesis class\n",
    "$$\n",
    "\\mathcal{H} =\n",
    "\\left\\{ h: \\mathcal{X}\\rightarrow\\mathcal{Y}\n",
    "~\\vert~\n",
    "h(\\vec{x}) = \\varphi(\\vectr{w}\\vec{x}+b); \\vec{w}\\in\\set{R}^D,~b\\in\\set{R}\\right\\}\n",
    "$$\n",
    "where $\\varphi(\\cdot)$ is some nonlinear function, is known as the **perceptron** model, and is also called a **neuron** in the context of a neural network (due to it's biologically-inspired origin).\n",
    "\n",
    "\n",
    "| . | . |\n",
    "|---|---|\n",
    "| <img src=\"imgs/perceptron.png\" width=400 /> | <img src=\"imgs/neuron.png\" width=600 /> |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A **pointwise loss function** is some $\\ell:\\mathcal{Y}\\times\\mathcal{Y}\\to\\set{R}_{\\geq 0}$, e.g.\n",
    "- $\\ell(y,\\hat{y})=(y-\\hat{y})^2$\n",
    "- $\\ell(y,\\hat{y})= -y\\log(\\hat{y})-(1-y)\\log(1-\\hat{y})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The task: Given the training set $\\mathcal{S} = \\{ (\\vec{x}^i,y^i) \\}_{i=1}^N \\sim \\mathcal{D}$, find \n",
    "a predictor (hypothesis) $h: \\mathcal{X}\\to\\mathcal{Y}$ which minimizes **population loss**:\n",
    "\n",
    "$$\n",
    "L_{\\mathcal{D}}(h) = \\E[(\\vec{x},y)\\sim\\mathcal{D}]{\\ell(y, h(\\vec{x})}.\n",
    "$$\n",
    "\n",
    "This is also known as the **out-of-sample** loss. It is a deterministic quantity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Yes, it's the true expectation of an RV.\n",
    "\n",
    "Can we solve this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Joint-distribution $\\mathcal{D}$ is unknown!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Instead, we define an **empirical (in-sample) loss** $L_{\\mathcal{S}}(h)$ as the measure of how well a function $h\\in\\mathcal{H}$ fits the data $\\mathcal{S}$, for example\n",
    "$$\n",
    "L_{\\mathcal{S}}(h) = \\frac{1}{N} \\sum_{i=1}^{N} \\ell(h(\\vec{x}^i), y^i) + R(h)\n",
    "$$\n",
    "where\n",
    "\n",
    "- $\\ell(y,\\hat{y})$ is some pointwise loss (depends on the data).\n",
    "- $R(h)$ is a regularization term (depends only on the model).\n",
    "\n",
    "Is this is a deterministic quantity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The model is **trained** by updating its parameters to improve its performance on some data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We wish to find a parametrization $\\vec{w}^\\ast$ of our model $h^{\\ast}_{\\mathcal{S}}(\\vec{x};\\vec{w}^\\ast)\\in\\mathcal{H}$ such that\n",
    "$$\n",
    "h^{\\ast}_{\\mathcal{S}} = \\arg\\min_{h\\in\\mathcal{H}} L_{\\mathcal{S}}(h)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Usual approach: descent-based optimization (will be covered in next lecture)\n",
    "$$\n",
    "\\vec{w}_{k+1} \\leftarrow \\vec{w}_{k} - \\eta_k \\vec{d}_{k}\n",
    "$$\n",
    "\n",
    "Where $\\vec{d}_k$ is a **descent direction** and $\\eta_k$ is the step size at step $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Most common choice for $\\vec{d}_k$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Gradient descent: $\\vec{d}_k = \\nabla_{\\vec{w}_{k}} L(\\vec{w}_{k})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Will we find the optimal solution, $\\vec{w}^\\ast$, though?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Generally the loss is non-convex and we have no guarantee of converging to the global optimum!\n",
    "$\\Rightarrow$ **Optimization Error**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/sgd2d_2.png\" width=800 /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Gradient descent (GD) has the advantage of being extremely simple to apply, and requires only first-order derivatives.\n",
    "\n",
    "However it provides no guarantees for convergence on non-convex objectives.\n",
    "\n",
    "Later in the course we'll learn about variants of GD which perform well in practice even on the non-convex objectives we'll face in deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Generalization and Expressiveness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We've talked about optimization error.\n",
    "\n",
    "What are **other** sources of errors in our learning approach (besides optimization)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We train to minimize our empirical loss $L_\\mathcal{S}$ instead of the population loss $L_\\mathcal{D}$ $\\Rightarrow$ **Generalization Error**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We only consider a limited set of possible functions, $\\mathcal{H}$ $\\Rightarrow$ **Approximation Error**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/error_types.png\" width=900 /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How do we mitigate these errors in the practice of machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Optimization error: Mini batches; GD variants like stochastic gradient, Momentum, Adam, LR scheduling, etc (we'll see later in the course)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Generalization error: Get more data; get data which better represents $\\mathcal{D}$; train-test splits; cross validation; early stopping; regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Approximation error: Use a powerful hypothesis class (e.g. DNN); more parameters; \"inductive bias\" - tailoring the model to the domain (e.g. CNN for images)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Binary Logistic Regression\n",
    "\n",
    "Actually a **classification** model. We're trying to classify data into 2 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Domain: $\\vec{x}^i \\in \\set{R}^D$\n",
    "- Target: $y^i \\in \\{0,1\\}$\n",
    "- Model: $\\hat{y} = h(\\vec{x}) = \\sigma(\\vectr{w}\\vec{x}+b)$, where $\\sigma(\\vec{z})$ is the **logistic function**:\n",
    "    $$\\sigma(\\vec{z}) = \\frac{1}{1+e^{-\\vec{z}}}.$$\n",
    "    This function maps the real line onto $[0,1]$.\n",
    "- Probabilistic interpretation: $\\hat{y}=P(\\rvar{Y}=1|\\rvec{X}=\\vec{x})$.\n",
    "\n",
    "  This is a posterior probability function for our target variable $\\rvar{Y}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:21.806138Z",
     "iopub.status.busy": "2022-03-31T05:57:21.806020Z",
     "iopub.status.idle": "2022-03-31T05:57:21.821968Z",
     "shell.execute_reply": "2022-03-31T05:57:21.821667Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def logistic(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "x = np.arange(-5, 5, .01)\n",
    "y_hat = logistic(x)\n",
    "\n",
    "plt.plot(x, y_hat, label='$\\sigma(z)$')\n",
    "plt.grid(True); plt.xlabel('z'); plt.legend(); plt.title('The logistic function');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To optimize, we minimize the **negative log-likelihood** (equivalent to maximizing likelihood, i.e. MLE) of the parameters $\\vec{w}$:\n",
    "\n",
    "$$\n",
    "\\bb{w}^\\ast = \\mathrm{arg}\\max_{ \\bb{w}} \\prod_{i=1}^n P(y_i | \\bb{x}_i;\\vec{w}) = \\mathrm{arg}\\min_{ \\bb{w}} \\sum_{i=1}^n -\\log P(y_i | \\bb{x}_i; \\vec{w})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Based on this we define our loss $L(\\bb{w})$ (what we minimize) as,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "L(\\bb{w}) &\\triangleq \\sum_{i=1}^n -\\log P(y_i | \\bb{x}_i; \\vec{w})\\\\\n",
    "&= \\sum_{i=1}^n -y_i \\log P(y_i=1 | \\bb{x}_i; \\vec{w}) - (1-y_i) \\log P(y_i=0 | \\bb{x}_i; \\vec{w}) \\\\\n",
    "&= \\sum_{i=1}^n -y_i \\log \\hat{y}_i - (1-y_i) \\log(1-\\hat{y}_i)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The resulting pointwise loss is also known as **cross-entropy**:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\ell(y, \\hat{y}) &=  - y \\log(\\hat{y}) - (1-y) \\log(1-\\hat{y}) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "(The \"cross\" here is between the distribution of the samples $y^i$ and the distribution of the predictions $\\hat{y}^i$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Optimization scheme: No closed form solution, but loss is **convex** so gradient-based approach leads to global optimum.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\ell(y, \\hat{y}) &=  - y \\log(\\hat{y}) - (1-y) \\log(1-\\hat{y}) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Let's plot this loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:22.046901Z",
     "iopub.status.busy": "2022-03-31T05:57:22.046787Z",
     "iopub.status.idle": "2022-03-31T05:57:22.158748Z",
     "shell.execute_reply": "2022-03-31T05:57:22.158430Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_y0 = -np.log(1-y_hat)\n",
    "loss_y1 = -np.log(y_hat)\n",
    "plt.plot(y_hat, loss_y0, label='$\\ell(y=0,\\hat{y})$')\n",
    "plt.plot(y_hat, loss_y1, label='$\\ell(y=1,\\hat{y})$')\n",
    "plt.grid(True); plt.xlabel('$\\hat{y}$'); plt.legend(); plt.title('Cross entropy loss');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To apply gradient descent, we need to know the gradient of the loss w.r.t. the parameters $\\vec{w}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Exercise: Prove that for the cross entropy loss with binary logistic regression, it holds that:\n",
    "$$\n",
    "\\pderiv{\\ell(y,\\hat{y})}{\\vec{w}}= (\\hat{y}-y)\\vec{x}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Proof:\n",
    "\n",
    "First, we apply the chain-rule\n",
    "$$\n",
    "\\pderiv{\\ell(y,\\hat{y})}{\\vec{w}}=\\pderiv{\\ell}{\\hat{y}}\\cdot\\pderiv{\\hat{y}}{z}\\cdot\\pderiv{z}{\\vec{w}},\n",
    "$$\n",
    "where $z=\\vectr{w}\\vec{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Now, just by definition,\n",
    "$$\n",
    "\\begin{align}\n",
    "\\pderiv{\\ell}{\\hat{y}}&=-\\frac{y}{\\hat{y}}+\\frac{1-y}{1-\\hat{y}}=\\frac{\\hat{y}-y}{\\hat{y}(1-\\hat{y})}\\\\\n",
    "\\pderiv{\\hat{y}}{z}&=\\frac{e^{-z}}{(1+e^{-z})^2}=\n",
    "\\frac{e^{-z}}{1+e^{-z}}\\cdot\\frac{1}{1+e^{-z}}=(1-\\sigma(z))\\sigma(z)=(1-\\hat{y})\\hat{y}\\\\\n",
    "\\pderiv{z}{\\vec{w}}&=\\vec{x}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 1: Binary Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As a warm up exercise, let's see a quick example of implementing this algorithm and training it from scratch using just `numpy` (and a toy dataset from `sklearn`).\n",
    "\n",
    "This is a classic and very simple example of implementing and training a machine learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dataset\n",
    "\n",
    "The `scikit-learn` library comes with a few [toy datasets](http://scikit-learn.org/stable/datasets/index.html#toy-datasets) that are fun to quickly train small models on.\n",
    "\n",
    "As an example we'll load the Wisconsin-breast cancer database:\n",
    "- 569 samples of cancer patients\n",
    "- 30 features: various properties of tumor cells extracted from images\n",
    "- 2 classes: Tumor is either Benign or Malignant\n",
    "\n",
    "We'll apply the basic machine learning approach we saw above: binary logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:22.160877Z",
     "iopub.status.busy": "2022-03-31T05:57:22.160761Z",
     "iopub.status.idle": "2022-03-31T05:57:22.305758Z",
     "shell.execute_reply": "2022-03-31T05:57:22.305466Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features=30\n",
      "feature names: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "target  names: ['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets\n",
    "\n",
    "ds_cancer = sklearn.datasets.load_breast_cancer()\n",
    "feature_names = ds_cancer.feature_names\n",
    "target_names = ds_cancer.target_names\n",
    "n_features = len(feature_names)\n",
    "\n",
    "print(f'{n_features=}')\n",
    "print(f'feature names: {feature_names}')\n",
    "print(f'target  names: {target_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:22.307551Z",
     "iopub.status.busy": "2022-03-31T05:57:22.307445Z",
     "iopub.status.idle": "2022-03-31T05:57:22.324556Z",
     "shell.execute_reply": "2022-03-31T05:57:22.324276Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (569, 30)\n",
      "y: (569,)\n"
     ]
    }
   ],
   "source": [
    "X, y = ds_cancer.data, ds_cancer.target\n",
    "n_samples = len(y)\n",
    "\n",
    "print(f'X: {X.shape}')\n",
    "print(f'y: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:22.326309Z",
     "iopub.status.busy": "2022-03-31T05:57:22.326189Z",
     "iopub.status.idle": "2022-03-31T05:57:22.351440Z",
     "shell.execute_reply": "2022-03-31T05:57:22.351125Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>13.610</td>\n",
       "      <td>582.7</td>\n",
       "      <td>0.08625</td>\n",
       "      <td>0.05871</td>\n",
       "      <td>2.8610</td>\n",
       "      <td>0.014880</td>\n",
       "      <td>0.01465</td>\n",
       "      <td>35.27</td>\n",
       "      <td>0.1265</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>MALIGNANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>6.981</td>\n",
       "      <td>143.5</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.07818</td>\n",
       "      <td>1.5530</td>\n",
       "      <td>0.010840</td>\n",
       "      <td>0.02659</td>\n",
       "      <td>19.54</td>\n",
       "      <td>0.1584</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>12.180</td>\n",
       "      <td>458.7</td>\n",
       "      <td>0.02383</td>\n",
       "      <td>0.05677</td>\n",
       "      <td>1.1830</td>\n",
       "      <td>0.006098</td>\n",
       "      <td>0.01447</td>\n",
       "      <td>32.84</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>9.876</td>\n",
       "      <td>298.3</td>\n",
       "      <td>0.06154</td>\n",
       "      <td>0.06322</td>\n",
       "      <td>1.5280</td>\n",
       "      <td>0.021960</td>\n",
       "      <td>0.01609</td>\n",
       "      <td>26.83</td>\n",
       "      <td>0.1559</td>\n",
       "      <td>0.09749</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>10.490</td>\n",
       "      <td>336.1</td>\n",
       "      <td>0.02995</td>\n",
       "      <td>0.06481</td>\n",
       "      <td>2.3020</td>\n",
       "      <td>0.022190</td>\n",
       "      <td>0.02710</td>\n",
       "      <td>23.31</td>\n",
       "      <td>0.1219</td>\n",
       "      <td>0.03203</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>13.110</td>\n",
       "      <td>530.2</td>\n",
       "      <td>0.20710</td>\n",
       "      <td>0.07692</td>\n",
       "      <td>2.4100</td>\n",
       "      <td>0.029120</td>\n",
       "      <td>0.01547</td>\n",
       "      <td>22.40</td>\n",
       "      <td>0.1862</td>\n",
       "      <td>0.19860</td>\n",
       "      <td>MALIGNANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>11.640</td>\n",
       "      <td>412.5</td>\n",
       "      <td>0.07070</td>\n",
       "      <td>0.06520</td>\n",
       "      <td>2.1550</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>0.01565</td>\n",
       "      <td>29.26</td>\n",
       "      <td>0.1688</td>\n",
       "      <td>0.12180</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>12.360</td>\n",
       "      <td>466.7</td>\n",
       "      <td>0.02643</td>\n",
       "      <td>0.06066</td>\n",
       "      <td>0.8484</td>\n",
       "      <td>0.010470</td>\n",
       "      <td>0.01251</td>\n",
       "      <td>27.49</td>\n",
       "      <td>0.1184</td>\n",
       "      <td>0.08442</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>22.270</td>\n",
       "      <td>1509.0</td>\n",
       "      <td>0.42640</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>10.0500</td>\n",
       "      <td>0.086680</td>\n",
       "      <td>0.03112</td>\n",
       "      <td>28.01</td>\n",
       "      <td>0.1701</td>\n",
       "      <td>0.29100</td>\n",
       "      <td>MALIGNANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>11.340</td>\n",
       "      <td>396.5</td>\n",
       "      <td>0.05133</td>\n",
       "      <td>0.06529</td>\n",
       "      <td>1.5970</td>\n",
       "      <td>0.015570</td>\n",
       "      <td>0.01568</td>\n",
       "      <td>29.15</td>\n",
       "      <td>0.1699</td>\n",
       "      <td>0.08278</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean area  mean concavity  mean fractal dimension  \\\n",
       "100       13.610      582.7         0.08625                 0.05871   \n",
       "101        6.981      143.5         0.00000                 0.07818   \n",
       "102       12.180      458.7         0.02383                 0.05677   \n",
       "103        9.876      298.3         0.06154                 0.06322   \n",
       "104       10.490      336.1         0.02995                 0.06481   \n",
       "105       13.110      530.2         0.20710                 0.07692   \n",
       "106       11.640      412.5         0.07070                 0.06520   \n",
       "107       12.360      466.7         0.02643                 0.06066   \n",
       "108       22.270     1509.0         0.42640                 0.07039   \n",
       "109       11.340      396.5         0.05133                 0.06529   \n",
       "\n",
       "     perimeter error  compactness error  symmetry error  worst texture  \\\n",
       "100           2.8610           0.014880         0.01465          35.27   \n",
       "101           1.5530           0.010840         0.02659          19.54   \n",
       "102           1.1830           0.006098         0.01447          32.84   \n",
       "103           1.5280           0.021960         0.01609          26.83   \n",
       "104           2.3020           0.022190         0.02710          23.31   \n",
       "105           2.4100           0.029120         0.01547          22.40   \n",
       "106           2.1550           0.023100         0.01565          29.26   \n",
       "107           0.8484           0.010470         0.01251          27.49   \n",
       "108          10.0500           0.086680         0.03112          28.01   \n",
       "109           1.5970           0.015570         0.01568          29.15   \n",
       "\n",
       "     worst smoothness  worst concave points      CLASS  \n",
       "100            0.1265               0.11840  MALIGNANT  \n",
       "101            0.1584               0.00000     BENIGN  \n",
       "102            0.1123               0.07431     BENIGN  \n",
       "103            0.1559               0.09749     BENIGN  \n",
       "104            0.1219               0.03203     BENIGN  \n",
       "105            0.1862               0.19860  MALIGNANT  \n",
       "106            0.1688               0.12180     BENIGN  \n",
       "107            0.1184               0.08442     BENIGN  \n",
       "108            0.1701               0.29100  MALIGNANT  \n",
       "109            0.1699               0.08278     BENIGN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load into a pandas dataframe and show some samples\n",
    "y_names = np.full_like(y, target_names[0].upper(), dtype=target_names.dtype)\n",
    "y_names[y==1] = target_names[1].upper()\n",
    "\n",
    "df_cancer = pd.DataFrame(data=X, columns=ds_cancer.feature_names)\n",
    "df_cancer = df_cancer.assign(CLASS=y_names)\n",
    "df_cancer.iloc[100:110, 0::3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:22.353134Z",
     "iopub.status.busy": "2022-03-31T05:57:22.353029Z",
     "iopub.status.idle": "2022-03-31T05:57:22.426369Z",
     "shell.execute_reply": "2022-03-31T05:57:22.426076Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: X=(398, 30) y=(398,)\n",
      "test : X=(171, 30) y=(171,)\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(f'train: X={X_train.shape} y={y_train.shape}')\n",
    "print(f'test : X={X_test.shape} y={y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:22.428140Z",
     "iopub.status.busy": "2022-03-31T05:57:22.428029Z",
     "iopub.status.idle": "2022-03-31T05:57:22.445197Z",
     "shell.execute_reply": "2022-03-31T05:57:22.444944Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu_X.shape=(30,), sigma_X.shape=(30,)\n"
     ]
    }
   ],
   "source": [
    "# Standardize the features\n",
    "\n",
    "# Note: each feature is standardized individually:\n",
    "mu_X = np.mean(X_train, axis=0) # (N, D) -> (D,)\n",
    "sigma_X = np.std(X_train, axis=0)\n",
    "\n",
    "# Note: Broadcasting (N, D) with (D,) -> (N, D)\n",
    "X_train_sc = (X_train - mu_X) / sigma_X \n",
    "\n",
    "# Note: Test set must be transformed identically to training set\n",
    "X_test_sc = (X_test - mu_X) / sigma_X\n",
    "\n",
    "print(f'{mu_X.shape=}, {sigma_X.shape=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Implementation\n",
    "\n",
    "We'll implement based on the above definitions.\n",
    "\n",
    "The model will be implemented as a class with an API that conforms to the `sklearn` models, specifically see\n",
    "`sklearn`'s [`LogisticRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression) class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:22.446969Z",
     "iopub.status.busy": "2022-03-31T05:57:22.446870Z",
     "iopub.status.idle": "2022-03-31T05:57:22.465612Z",
     "shell.execute_reply": "2022-03-31T05:57:22.465336Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryLogisticRegression(object):\n",
    "    def __init__(self, n_iter=100, learn_rate=0.1):\n",
    "        self.n_iter = n_iter\n",
    "        self.learn_rate = learn_rate\n",
    "        self._w = None\n",
    "        \n",
    "    def _add_bias(self, X: np.ndarray):\n",
    "        # Add a bias term column\n",
    "        ones_col = np.ones((X.shape[0], 1))\n",
    "        return np.hstack([ones_col, X])\n",
    "    \n",
    "    def predict_proba(self, X: np.ndarray, add_bias=True):\n",
    "        X = self._add_bias(X) if add_bias else X\n",
    "        \n",
    "        # Apply logistic model\n",
    "        z = np.dot(X, self.weights) # (N, D) * (D,)\n",
    "        return logistic(z) # shape (N,)\n",
    "    \n",
    "    def predict(self, X: np.ndarray):\n",
    "        proba = self.predict_proba(X)\n",
    "        \n",
    "        # Apply naive threshold of .5\n",
    "        return np.array(proba > .5, dtype=np.int)\n",
    "    \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        n, d = X.shape # X is (N, D), y is (N,)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._w = np.random.randn(d + 1) * 0.1\n",
    "        \n",
    "        Xb = self._add_bias(X)\n",
    "\n",
    "        # Training loop\n",
    "        self._losses = []\n",
    "        for i in range(self.n_iter):\n",
    "            # Predicted probabilities\n",
    "            y_hat = self.predict_proba(Xb, add_bias=False)\n",
    "            \n",
    "            # Pointwise loss\n",
    "            loss = -y.dot(np.log(y_hat)) - ((1 - y).dot(np.log(1 - y_hat)))\n",
    "            \n",
    "            # See Exercise for gradient derivation\n",
    "            loss_grad = 1/n * Xb.T.dot(y_hat - y)  # dl/dw: (D+1, N) * (N,)\n",
    "            \n",
    "            # Optimization step\n",
    "            self._w += -self.learn_rate * loss_grad\n",
    "            self._losses.append(loss)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    @property\n",
    "    def weights(self):\n",
    "        if self._w is None:\n",
    "            raise ValueError(\"Model is not fitted\")\n",
    "        return self._w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:22.467358Z",
     "iopub.status.busy": "2022-03-31T05:57:22.467275Z",
     "iopub.status.idle": "2022-03-31T05:57:22.563355Z",
     "shell.execute_reply": "2022-03-31T05:57:22.563067Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "lr_model = BinaryLogisticRegression(n_iter=500, learn_rate=0.01)\n",
    "lr_model.fit(X_train_sc, y_train)\n",
    "\n",
    "plt.plot(lr_model._losses, label='$L_{\\mathcal{S}}$');\n",
    "plt.xlabel('training iteration'); plt.legend(); plt.grid(True); plt.title('Train loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:22.565187Z",
     "iopub.status.busy": "2022-03-31T05:57:22.565084Z",
     "iopub.status.idle": "2022-03-31T05:57:22.581336Z",
     "shell.execute_reply": "2022-03-31T05:57:22.581061Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set accuracy: 97.74%\n",
      "test set accuracy: 98.25%\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = lr_model.predict(X_train_sc)\n",
    "train_acc = np.mean(y_train_pred == y_train)\n",
    "print(f'train set accuracy: {train_acc*100:.2f}%')\n",
    "\n",
    "y_test_pred = lr_model.predict(X_test_sc)\n",
    "test_acc = np.mean(y_test_pred == y_test)\n",
    "print(f'test set accuracy: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 2: Multiclass Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What if we have $C$ classes? Can we still use logistic regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A naïve approach is to train $C$ binary logistic regression classifiers, for example in a One vs. Rest scheme,\n",
    "and then predict based on the classifier returning the greatest probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "One major drawback of this approach is that it doesn't model the probability distribution over the possible classes, $P_{\\vec{Y}|\\vec{X}}$. \n",
    "\n",
    "For example, a sample might be classified as class A with probability $0.8$ and class $B$ with $0.7$ since nothing constrains the different classifiers.\n",
    "\n",
    "Also, without *calibrating* each model, their raw scores cannont reliably be compared even though they're in the same range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The softmax function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Softmax** is a function which can generate a probability distribution for our $C$ classes given raw prediction scores. It's defined as follows:\n",
    "\n",
    "$$\n",
    "\\mathrm{softmax}(\\vec{z}) = \\frac{e^{\\vec{z}}}{\\sum_{j=1}^{C} e^{z_j}}\n",
    "$$\n",
    "\n",
    "note that this is a vector valued, multivariate function. The exponent in the enumerator operates elementwise.\n",
    "\n",
    "The result of softmax is a vector with elements in $[0,1]$ that all sum to $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The multiclass model\n",
    "\n",
    "Our model can now be defined as\n",
    "\n",
    "$$\\hat{\\vec{y}} = h(\\vec{x}) = \\mathrm{softmax}(\\mattr{W}\\vec{x}+\\vec{b})$$\n",
    "\n",
    "where,\n",
    "- $\\hat{\\vec{y}}$ is a $C\\times 1$ vector of class probabilities.\n",
    "- ${\\vec{x}}$ is a $D\\times 1$ sample.\n",
    "- $\\mat{W}$ is a $D\\times C$ matrix representing the per-class weights.\n",
    "- $\\vec{b}$ is a per-class bias vector of length $C$.\n",
    "\n",
    "Probabilistic interpretation: $\\hat{y}_j = P(\\rvar{Y}=j|\\rvec{X}=\\vec{x})$.\n",
    "\n",
    "While not very powerful on it's own, this type of model is commonly found at the end of deep neural networks performing classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To train such a model we need our labels to also be singleton probability distributions instead of simply the number of the correct class.\n",
    "\n",
    "We'll transform our labels to a 1-hot encoded vector corresponding to a delta distribution.\n",
    "For example, if $y^i=j$ then we'll create\n",
    "$$\n",
    "\\vec{y}^i = [0,\\dots,0,\\underbrace{1}_{j\\mathrm{th\\ component}},0,\\dots,0]^\\top\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Cross-Entropy loss\n",
    "\n",
    "After defining the 1-hot label vectors, the multiclass extension of the binary cross-entropy is straightforward:\n",
    "\n",
    "$$\n",
    "\\ell(\\vec{y}, \\hat{\\vec{y}}) = - \\vectr{y} \\log(\\hat{\\vec{y}})\n",
    "$$\n",
    "\n",
    "Note that only the probability assigned to the correct class affects the loss.\n",
    "\n",
    "Minimizing this cross entropy can be interpreted as trying to move the probability distribution of model predictions towards the singleton distribution of the appropriate class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This time we'll tackle an image classification task, the MNIST database of handwritten digits.\n",
    "\n",
    "Today this is also considered a toy dataset, even though it was used in the past to benchmark classification algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:22.583530Z",
     "iopub.status.busy": "2022-03-31T05:57:22.583432Z",
     "iopub.status.idle": "2022-03-31T05:57:23.673426Z",
     "shell.execute_reply": "2022-03-31T05:57:23.673015Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.autograd\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms\n",
    "import plot_utils\n",
    "\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:23.675467Z",
     "iopub.status.busy": "2022-03-31T05:57:23.675341Z",
     "iopub.status.idle": "2022-03-31T05:57:23.728446Z",
     "shell.execute_reply": "2022-03-31T05:57:23.728149Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Define the transforms that should be applied to each image in the dataset before returning it\n",
    "tf_ds = torchvision.transforms.ToTensor()\n",
    "\n",
    "batch_size = 64\n",
    "data_root = os.path.expanduser(\"~/.pytorch-datasets\")\n",
    "\n",
    "# Training and test datasets\n",
    "ds_train, ds_test = [\n",
    "    torchvision.datasets.MNIST(root=data_root, download=True, train=train, transform=tf_ds)   \n",
    "    for train in [True, False]\n",
    "]\n",
    "\n",
    "# Data loaders\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size, shuffle=True)\n",
    "dl_test = torch.utils.data.DataLoader(ds_test, batch_size=len(ds_test))\n",
    "\n",
    "x0, y0 = ds_train[0]\n",
    "n_features = torch.numel(x0)\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:23.730338Z",
     "iopub.status.busy": "2022-03-31T05:57:23.730231Z",
     "iopub.status.idle": "2022-03-31T05:57:23.909829Z",
     "shell.execute_reply": "2022-03-31T05:57:23.909349Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0: torch.Size([1, 28, 28]), y0: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show first few samples\n",
    "print(f'x0: {x0.shape}, y0: {y0}')\n",
    "plot_utils.dataset_first_n(ds_train, 10, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that when training, we're actually working with **batches** of samples (we'll learn about SGD in the sebsequent lectures/tutorials):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:23.911944Z",
     "iopub.status.busy": "2022-03-31T05:57:23.911831Z",
     "iopub.status.idle": "2022-03-31T05:57:23.950133Z",
     "shell.execute_reply": "2022-03-31T05:57:23.949826Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0, y0 = next(iter(dl_train))\n",
    "x0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This time we'll use `pytorch` tensors and its [`autograd`](https://pytorch.org/docs/stable/autograd.html) functionality to implement our model.\n",
    "\n",
    "This means we wont have to implement any gradient calculations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "First, let's implement $\\mathrm{softmax}(\\cdot)$. We need a small numerical trick to prevent large numbers from exploding the exponentiation. You can verify that this doesn't influence the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:23.952303Z",
     "iopub.status.busy": "2022-03-31T05:57:23.952173Z",
     "iopub.status.idle": "2022-03-31T05:57:23.974439Z",
     "shell.execute_reply": "2022-03-31T05:57:23.974110Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def softmax(z: Tensor) -> Tensor:\n",
    "    \"\"\"\n",
    "    softmax(z)= e^(z) / sum(e^z)\n",
    "    :param z: A batch of C class scores per N samples, shape (N, C).\n",
    "    :returns: softmax per sample, of shape (N, C).\n",
    "    \"\"\"\n",
    "\n",
    "    # normalization trick to prevent numerical instability:\n",
    "    # shift so that the highest class score (per sample) is 0\n",
    "    zmax, _ = torch.max(z, dim=1, keepdim=True)\n",
    "    z = z - zmax # note broadcasting: (N,C) - (N,1)\n",
    "    \n",
    "    exp_z = torch.exp(z) # (N, C)\n",
    "    sum_exp = torch.sum(exp_z, dim=1, keepdim=True) # (N, 1)\n",
    "    return exp_z / sum_exp # probabilities, (N,C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's test our softmax and calculate its derivative with `autograd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:23.976580Z",
     "iopub.status.busy": "2022-03-31T05:57:23.976457Z",
     "iopub.status.idle": "2022-03-31T05:57:24.016133Z",
     "shell.execute_reply": "2022-03-31T05:57:24.015840Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2205, 0.0566, 0.7229],\n",
       "        [0.7395, 0.1037, 0.1568],\n",
       "        [0.3643, 0.1258, 0.5099],\n",
       "        [0.5928, 0.0752, 0.3321]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.randn(size=(4,3), requires_grad=True)\n",
    "y = softmax(z)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:24.017936Z",
     "iopub.status.busy": "2022-03-31T05:57:24.017817Z",
     "iopub.status.idle": "2022-03-31T05:57:24.046073Z",
     "shell.execute_reply": "2022-03-31T05:57:24.045800Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 2.1002e-08, -8.3615e-09, -1.2640e-08],\n",
       "         [ 4.2578e-08,  1.4709e-08, -5.7287e-08],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]),)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = softmax(z)\n",
    "L = torch.sum(y) # scalar function of z \n",
    "\n",
    "# Calculate gradient: dL/dz\n",
    "torch.autograd.grad(L, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Instead of calling `autograd.grad()` directly with specific input tensors, `pytorch` provides us with a way to calculate the derivative of a tensor w.r.t. all the tensors which are **leaves** in it's computation graph (only $\\vec{z}$ in this case).\n",
    "\n",
    "This can be done by calling `.backward()` on a scalar tensor.\n",
    "As a result, the `.grad` property of leaf tensors will be populated with the gradient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:24.047850Z",
     "iopub.status.busy": "2022-03-31T05:57:24.047737Z",
     "iopub.status.idle": "2022-03-31T05:57:24.069034Z",
     "shell.execute_reply": "2022-03-31T05:57:24.068735Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 2.0473e-08, -3.4802e-08,  1.4329e-08],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]),\n",
       " tensor([[-2.0473e-08,  3.4802e-08, -1.4329e-08]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example with two leaves in the computaion graph\n",
    "z1 = torch.randn(size=(4,3), requires_grad=True)\n",
    "z2 = torch.randn(size=(1,3), requires_grad=True)\n",
    "z = z1 - z2\n",
    "\n",
    "y = softmax(z)\n",
    "L = torch.sum(y) # scalar function of z \n",
    "L.backward()     # Calculate derivative w.r.t. all leaves\n",
    "\n",
    "z1.grad, z2.grad # The leaves z1, z2 will have their .grad populated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here's the resulting computation graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:24.070855Z",
     "iopub.status.busy": "2022-03-31T05:57:24.070744Z",
     "iopub.status.idle": "2022-03-31T05:57:24.189514Z",
     "shell.execute_reply": "2022-03-31T05:57:24.189143Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"228pt\" height=\"545pt\"\r\n",
       " viewBox=\"0.00 0.00 228.00 545.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 541)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-541 224,-541 224,4 -4,4\"/>\r\n",
       "<!-- 2441027559552 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>2441027559552</title>\r\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"136.5,-31 82.5,-31 82.5,-0 136.5,-0 136.5,-31\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"109.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\r\n",
       "</g>\r\n",
       "<!-- 2441027643520 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>2441027643520</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"154,-86 65,-86 65,-67 154,-67 154,-86\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"109.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">SumBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2441027643520&#45;&gt;2441027559552 -->\r\n",
       "<g id=\"edge13\" class=\"edge\"><title>2441027643520&#45;&gt;2441027559552</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M109.5,-66.7943C109.5,-60.0669 109.5,-50.404 109.5,-41.3425\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"113,-41.1932 109.5,-31.1933 106,-41.1933 113,-41.1932\"/>\r\n",
       "</g>\r\n",
       "<!-- 2441027643376 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2441027643376</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"154,-141 65,-141 65,-122 154,-122 154,-141\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"109.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">DivBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2441027643376&#45;&gt;2441027643520 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>2441027643376&#45;&gt;2441027643520</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M109.5,-121.748C109.5,-114.802 109.5,-104.845 109.5,-96.1349\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"113,-96.089 109.5,-86.089 106,-96.0891 113,-96.089\"/>\r\n",
       "</g>\r\n",
       "<!-- 2441027643760 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>2441027643760</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"151,-251 68,-251 68,-232 151,-232 151,-251\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"109.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">ExpBackward</text>\r\n",
       "</g>\r\n",
       "<!-- 2441027643760&#45;&gt;2441027643376 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>2441027643760&#45;&gt;2441027643376</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M105.134,-231.91C100.941,-223.142 94.901,-209.013 92.5,-196 89.6204,-180.393 94.8856,-163.004 100.297,-150.375\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"103.604,-151.567 104.701,-141.029 97.2717,-148.583 103.604,-151.567\"/>\r\n",
       "</g>\r\n",
       "<!-- 2441027645008 -->\r\n",
       "<g id=\"node12\" class=\"node\"><title>2441027645008</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"191,-196 102,-196 102,-177 191,-177 191,-196\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"146.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">SumBackward1</text>\r\n",
       "</g>\r\n",
       "<!-- 2441027643760&#45;&gt;2441027645008 -->\r\n",
       "<g id=\"edge12\" class=\"edge\"><title>2441027643760&#45;&gt;2441027645008</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M115.61,-231.748C120.782,-224.339 128.346,-213.504 134.694,-204.411\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"137.649,-206.292 140.504,-196.089 131.91,-202.285 137.649,-206.292\"/>\r\n",
       "</g>\r\n",
       "<!-- 2441027643712 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>2441027643712</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"154,-306 65,-306 65,-287 154,-287 154,-306\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"109.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\">SubBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2441027643712&#45;&gt;2441027643760 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>2441027643712&#45;&gt;2441027643760</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M109.5,-286.748C109.5,-279.802 109.5,-269.845 109.5,-261.135\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"113,-261.089 109.5,-251.089 106,-261.089 113,-261.089\"/>\r\n",
       "</g>\r\n",
       "<!-- 2441027643952 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>2441027643952</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"154,-416 65,-416 65,-397 154,-397 154,-416\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"109.5\" y=\"-404\" font-family=\"monospace\" font-size=\"10.00\">SubBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2441027643952&#45;&gt;2441027643712 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>2441027643952&#45;&gt;2441027643712</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M105.134,-396.91C100.941,-388.142 94.901,-374.013 92.5,-361 89.6204,-345.393 94.8856,-328.004 100.297,-315.375\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"103.604,-316.567 104.701,-306.029 97.2717,-313.583 103.604,-316.567\"/>\r\n",
       "</g>\r\n",
       "<!-- 2441027643424 -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>2441027643424</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"191,-361 102,-361 102,-342 191,-342 191,-361\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"146.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\">MaxBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2441027643952&#45;&gt;2441027643424 -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>2441027643952&#45;&gt;2441027643424</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M115.61,-396.748C120.782,-389.339 128.346,-378.504 134.694,-369.411\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"137.649,-371.292 140.504,-361.089 131.91,-367.285 137.649,-371.292\"/>\r\n",
       "</g>\r\n",
       "<!-- 2441027643904 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>2441027643904</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-471 0,-471 0,-452 101,-452 101,-471\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-459\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\r\n",
       "</g>\r\n",
       "<!-- 2441027643904&#45;&gt;2441027643952 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>2441027643904&#45;&gt;2441027643952</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M59.9794,-451.985C68.7011,-444.15 81.8435,-432.344 92.3978,-422.863\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"94.7479,-425.457 99.8481,-416.17 90.07,-420.249 94.7479,-425.457\"/>\r\n",
       "</g>\r\n",
       "<!-- 2441027530496 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>2441027530496</title>\r\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"80,-537 21,-537 21,-507 80,-507 80,-537\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-525\" font-family=\"monospace\" font-size=\"10.00\">z1</text>\r\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-514\" font-family=\"monospace\" font-size=\"10.00\"> (4, 3)</text>\r\n",
       "</g>\r\n",
       "<!-- 2441027530496&#45;&gt;2441027643904 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>2441027530496&#45;&gt;2441027643904</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-506.839C50.5,-499.214 50.5,-489.704 50.5,-481.45\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54.0001,-481.266 50.5,-471.266 47.0001,-481.266 54.0001,-481.266\"/>\r\n",
       "</g>\r\n",
       "<!-- 2441027643616 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>2441027643616</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"220,-471 119,-471 119,-452 220,-452 220,-471\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"169.5\" y=\"-459\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\r\n",
       "</g>\r\n",
       "<!-- 2441027643616&#45;&gt;2441027643952 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>2441027643616&#45;&gt;2441027643952</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M159.86,-451.985C150.99,-444.15 137.625,-432.344 126.892,-422.863\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"129.127,-420.168 119.315,-416.17 124.493,-425.414 129.127,-420.168\"/>\r\n",
       "</g>\r\n",
       "<!-- 2441027563200 -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>2441027563200</title>\r\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"199,-537 140,-537 140,-507 199,-507 199,-537\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"169.5\" y=\"-525\" font-family=\"monospace\" font-size=\"10.00\">z2</text>\r\n",
       "<text text-anchor=\"middle\" x=\"169.5\" y=\"-514\" font-family=\"monospace\" font-size=\"10.00\"> (1, 3)</text>\r\n",
       "</g>\r\n",
       "<!-- 2441027563200&#45;&gt;2441027643616 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>2441027563200&#45;&gt;2441027643616</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M169.5,-506.839C169.5,-499.214 169.5,-489.704 169.5,-481.45\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"173,-481.266 169.5,-471.266 166,-481.266 173,-481.266\"/>\r\n",
       "</g>\r\n",
       "<!-- 2441027643424&#45;&gt;2441027643712 -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>2441027643424&#45;&gt;2441027643712</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M140.39,-341.748C135.218,-334.339 127.654,-323.504 121.306,-314.411\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"124.09,-312.285 115.496,-306.089 118.351,-316.292 124.09,-312.285\"/>\r\n",
       "</g>\r\n",
       "<!-- 2441027645008&#45;&gt;2441027643376 -->\r\n",
       "<g id=\"edge11\" class=\"edge\"><title>2441027645008&#45;&gt;2441027643376</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M140.39,-176.748C135.218,-169.339 127.654,-158.504 121.306,-149.411\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"124.09,-147.285 115.496,-141.089 118.351,-151.292 124.09,-147.285\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x23858946190>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchviz\n",
    "torchviz.make_dot(L, params=dict(z1=z1, z2=z2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The next ingredient of the solution is the cross-entropy loss function.\n",
    "\n",
    "Recall that we need to encode our ground-truth labels as one-hot vectors to apply the multiclass cross-entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:24.191534Z",
     "iopub.status.busy": "2022-03-31T05:57:24.191440Z",
     "iopub.status.idle": "2022-03-31T05:57:24.216881Z",
     "shell.execute_reply": "2022-03-31T05:57:24.216509Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def cross_entropy_loss(y: Tensor, y_hat: Tensor, eps=1e-6):\n",
    "    \"\"\"\n",
    "    :param y:  Onehot-encoded ground-truth labels, shape (N, C)\n",
    "    :param y_hat: A batch of probabilities, shape (N,C)\n",
    "    :returns: Cross entropy between y and y_hat.\n",
    "    \"\"\"\n",
    "    return torch.sum( - y * torch.log(y_hat + eps) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:24.218798Z",
     "iopub.status.busy": "2022-03-31T05:57:24.218696Z",
     "iopub.status.idle": "2022-03-31T05:57:24.239370Z",
     "shell.execute_reply": "2022-03-31T05:57:24.239057Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def onehot(y: Tensor, n_classes: int) -> Tensor:\n",
    "    \"\"\"\n",
    "    Encodes y of shape (N,) containing class labels in the range [0,C-1] as one-hot of shape (N,C).\n",
    "    \"\"\"\n",
    "    y = y.reshape(-1, 1) # Reshape y to (N,1)\n",
    "    zeros = torch.zeros(size=(len(y), n_classes), dtype=torch.float32) # (N,C)\n",
    "    ones = torch.ones_like(y, dtype=torch.float32)\n",
    "    \n",
    "    # scatter: put items from 'src' into 'dest' at indices correspondnig to 'index' along 'dim'\n",
    "    y_onehot = torch.scatter(zeros, dim=1, index=y, src=ones)\n",
    "    \n",
    "    return y_onehot # result has shape (N, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:24.241335Z",
     "iopub.status.busy": "2022-03-31T05:57:24.241127Z",
     "iopub.status.idle": "2022-03-31T05:57:24.264310Z",
     "shell.execute_reply": "2022-03-31T05:57:24.264005Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot(torch.tensor([1, 3, 5, 0]), n_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Our model itself will just hold the parameters $\\mat{W}$ and $\\vec{b}$ and apply them to an input batch $\\mat{X}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:24.266157Z",
     "iopub.status.busy": "2022-03-31T05:57:24.266051Z",
     "iopub.status.idle": "2022-03-31T05:57:24.287258Z",
     "shell.execute_reply": "2022-03-31T05:57:24.286921Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class MCLogisticRegression(object):\n",
    "    def __init__(self, n_features: int, n_classes: int):\n",
    "        # Define our parameter tensors: notice that now W and b are separate\n",
    "        # Specify we want to track their gradients with autograd\n",
    "        self.W = torch.randn(n_features, n_classes, requires_grad=True)\n",
    "        self.b = torch.randn(n_classes, requires_grad=True)\n",
    "        self.params = [self.W, self.b]\n",
    "    \n",
    "    def __c all__(self, *args):\n",
    "        return self.forward(*args)\n",
    "\n",
    "    def forward(self, X: Tensor):\n",
    "        \"\"\"\n",
    "        :param X: A batch of samples, (N, D)\n",
    "        :return: A batch of class probabilities, (N, C)\n",
    "        \"\"\"\n",
    "        # X is (N, D), W is (D, C), b is (C,)\n",
    "        z = torch.mm(X, self.W) + self.b\n",
    "        y_hat = softmax(z)\n",
    "        return y_hat # (N, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's try out the model and loss on the first batch.\n",
    "\n",
    "Note that we naïvely treat each pixel as a separate feature. We'll learn how to properly work with images in a future tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:24.289076Z",
     "iopub.status.busy": "2022-03-31T05:57:24.288990Z",
     "iopub.status.idle": "2022-03-31T05:57:24.309803Z",
     "shell.execute_reply": "2022-03-31T05:57:24.309511Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0_flat: torch.Size([64, 784])\n",
      "y0_onehot: torch.Size([64, 10])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = MCLogisticRegression(n_features, n_classes)\n",
    "\n",
    "# Flatten images and convert labels to onehot\n",
    "x0_flat = x0.reshape(-1, n_features)\n",
    "y0_onehot =  onehot(y0, n_classes)\n",
    "\n",
    "print(f'x0_flat: {x0_flat.shape}')\n",
    "print(f'y0_onehot: {y0_onehot.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:24.311535Z",
     "iopub.status.busy": "2022-03-31T05:57:24.311432Z",
     "iopub.status.idle": "2022-03-31T05:57:24.341704Z",
     "shell.execute_reply": "2022-03-31T05:57:24.341414Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  tensor(549.1625, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Forward pass and compute loss\n",
    "y0_hat = model(x0_flat)\n",
    "loss = cross_entropy_loss(y0_onehot, y0_hat)\n",
    "print('loss = ', loss)\n",
    "\n",
    "# Backward pass to populate .grad on leaf nodes\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Since we specified `require_grad=True` for our model parameters, every operation performed on these tensors is recorded, and a **computation graph** can be built, which included the model and loss calculation.\n",
    "Notice that the **leaves** in this graph are our parameters $\\mat{W}$ and $\\vec{b}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:24.343575Z",
     "iopub.status.busy": "2022-03-31T05:57:24.343462Z",
     "iopub.status.idle": "2022-03-31T05:57:24.403420Z",
     "shell.execute_reply": "2022-03-31T05:57:24.403037Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"216pt\" height=\"776pt\"\r\n",
       " viewBox=\"0.00 0.00 216.00 776.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 772)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-772 212,-772 212,4 -4,4\"/>\r\n",
       "<!-- 2441028021312 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>2441028021312</title>\r\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"130.5,-31 76.5,-31 76.5,-0 130.5,-0 130.5,-31\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"103.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\r\n",
       "</g>\r\n",
       "<!-- 2441027544400 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>2441027544400</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"148,-86 59,-86 59,-67 148,-67 148,-86\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"103.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">SumBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2441027544400&#45;&gt;2441028021312 -->\r\n",
       "<g id=\"edge17\" class=\"edge\"><title>2441027544400&#45;&gt;2441028021312</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103.5,-66.7943C103.5,-60.0669 103.5,-50.404 103.5,-41.3425\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"107,-41.1932 103.5,-31.1933 100,-41.1933 107,-41.1932\"/>\r\n",
       "</g>\r\n",
       "<!-- 2441027546608 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2441027546608</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"148,-141 59,-141 59,-122 148,-122 148,-141\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"103.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2441027546608&#45;&gt;2441027544400 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>2441027546608&#45;&gt;2441027544400</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103.5,-121.748C103.5,-114.802 103.5,-104.845 103.5,-96.1349\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"107,-96.089 103.5,-86.089 100,-96.0891 107,-96.089\"/>\r\n",
       "</g>\r\n",
       "<!-- 2441027546800 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>2441027546800</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"145,-196 62,-196 62,-177 145,-177 145,-196\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"103.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">LogBackward</text>\r\n",
       "</g>\r\n",
       "<!-- 2441027546800&#45;&gt;2441027546608 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>2441027546800&#45;&gt;2441027546608</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103.5,-176.748C103.5,-169.802 103.5,-159.845 103.5,-151.135\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"107,-151.089 103.5,-141.089 100,-151.089 107,-151.089\"/>\r\n",
       "</g>\r\n",
       "<!-- 2441027545552 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>2441027545552</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"148,-251 59,-251 59,-232 148,-232 148,-251\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"103.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2441027545552&#45;&gt;2441027546800 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>2441027545552&#45;&gt;2441027546800</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103.5,-231.748C103.5,-224.802 103.5,-214.845 103.5,-206.135\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"107,-206.089 103.5,-196.089 100,-206.089 107,-206.089\"/>\r\n",
       "</g>\r\n",
       "<!-- 2441027545504 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>2441027545504</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"148,-306 59,-306 59,-287 148,-287 148,-306\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"103.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\">DivBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2441027545504&#45;&gt;2441027545552 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>2441027545504&#45;&gt;2441027545552</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103.5,-286.748C103.5,-279.802 103.5,-269.845 103.5,-261.135\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"107,-261.089 103.5,-251.089 100,-261.089 107,-261.089\"/>\r\n",
       "</g>\r\n",
       "<!-- 2441027546848 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>2441027546848</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"145,-416 62,-416 62,-397 145,-397 145,-416\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"103.5\" y=\"-404\" font-family=\"monospace\" font-size=\"10.00\">ExpBackward</text>\r\n",
       "</g>\r\n",
       "<!-- 2441027546848&#45;&gt;2441027545504 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>2441027546848&#45;&gt;2441027545504</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M99.134,-396.91C94.9413,-388.142 88.901,-374.013 86.5,-361 83.6204,-345.393 88.8856,-328.004 94.2966,-315.375\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"97.6039,-316.567 98.7006,-306.029 91.2717,-313.583 97.6039,-316.567\"/>\r\n",
       "</g>\r\n",
       "<!-- 2441027546080 -->\r\n",
       "<g id=\"node16\" class=\"node\"><title>2441027546080</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"185,-361 96,-361 96,-342 185,-342 185,-361\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"140.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\">SumBackward1</text>\r\n",
       "</g>\r\n",
       "<!-- 2441027546848&#45;&gt;2441027546080 -->\r\n",
       "<g id=\"edge16\" class=\"edge\"><title>2441027546848&#45;&gt;2441027546080</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M109.61,-396.748C114.782,-389.339 122.346,-378.504 128.694,-369.411\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"131.649,-371.292 134.504,-361.089 125.91,-367.285 131.649,-371.292\"/>\r\n",
       "</g>\r\n",
       "<!-- 2441027546944 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>2441027546944</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"148,-471 59,-471 59,-452 148,-452 148,-471\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"103.5\" y=\"-459\" font-family=\"monospace\" font-size=\"10.00\">SubBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2441027546944&#45;&gt;2441027546848 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>2441027546944&#45;&gt;2441027546848</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103.5,-451.748C103.5,-444.802 103.5,-434.845 103.5,-426.135\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"107,-426.089 103.5,-416.089 100,-426.089 107,-426.089\"/>\r\n",
       "</g>\r\n",
       "<!-- 2441027545888 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>2441027545888</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"148,-581 59,-581 59,-562 148,-562 148,-581\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"103.5\" y=\"-569\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2441027545888&#45;&gt;2441027546944 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>2441027545888&#45;&gt;2441027546944</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M98.7006,-561.971C92.4727,-549.873 82.8141,-526.977 86.5,-507 88.1694,-497.952 91.5984,-488.364 94.9423,-480.414\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"98.2259,-481.646 99.134,-471.09 91.8414,-478.776 98.2259,-481.646\"/>\r\n",
       "</g>\r\n",
       "<!-- 2441027545456 -->\r\n",
       "<g id=\"node15\" class=\"node\"><title>2441027545456</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"185,-526 96,-526 96,-507 185,-507 185,-526\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"140.5\" y=\"-514\" font-family=\"monospace\" font-size=\"10.00\">MaxBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2441027545888&#45;&gt;2441027545456 -->\r\n",
       "<g id=\"edge14\" class=\"edge\"><title>2441027545888&#45;&gt;2441027545456</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M109.61,-561.748C114.782,-554.339 122.346,-543.504 128.694,-534.411\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"131.649,-536.292 134.504,-526.089 125.91,-532.285 131.649,-536.292\"/>\r\n",
       "</g>\r\n",
       "<!-- 2440909506400 -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>2440909506400</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"89,-636 12,-636 12,-617 89,-617 89,-636\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-624\" font-family=\"monospace\" font-size=\"10.00\">MmBackward</text>\r\n",
       "</g>\r\n",
       "<!-- 2440909506400&#45;&gt;2441027545888 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>2440909506400&#45;&gt;2441027545888</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M59.2519,-616.748C66.9697,-609.03 78.4047,-597.595 87.7165,-588.283\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"90.3148,-590.635 94.911,-581.089 85.365,-585.685 90.3148,-590.635\"/>\r\n",
       "</g>\r\n",
       "<!-- 2440909508080 -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>2440909508080</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-696.5 0,-696.5 0,-677.5 101,-677.5 101,-696.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-684.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\r\n",
       "</g>\r\n",
       "<!-- 2440909508080&#45;&gt;2440909506400 -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>2440909508080&#45;&gt;2440909506400</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-677.368C50.5,-669.246 50.5,-656.807 50.5,-646.385\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54.0001,-646.167 50.5,-636.167 47.0001,-646.167 54.0001,-646.167\"/>\r\n",
       "</g>\r\n",
       "<!-- 2441028000448 -->\r\n",
       "<g id=\"node12\" class=\"node\"><title>2441028000448</title>\r\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"89,-768 12,-768 12,-738 89,-738 89,-768\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-756\" font-family=\"monospace\" font-size=\"10.00\">W</text>\r\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-745\" font-family=\"monospace\" font-size=\"10.00\"> (784, 10)</text>\r\n",
       "</g>\r\n",
       "<!-- 2441028000448&#45;&gt;2440909508080 -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>2441028000448&#45;&gt;2440909508080</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-737.796C50.5,-728.699 50.5,-716.788 50.5,-706.897\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54.0001,-706.844 50.5,-696.844 47.0001,-706.844 54.0001,-706.844\"/>\r\n",
       "</g>\r\n",
       "<!-- 2440909505632 -->\r\n",
       "<g id=\"node13\" class=\"node\"><title>2440909505632</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"208,-636 107,-636 107,-617 208,-617 208,-636\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"157.5\" y=\"-624\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\r\n",
       "</g>\r\n",
       "<!-- 2440909505632&#45;&gt;2441027545888 -->\r\n",
       "<g id=\"edge11\" class=\"edge\"><title>2440909505632&#45;&gt;2441027545888</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M148.583,-616.748C140.72,-609.03 129.069,-597.595 119.581,-588.283\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"121.84,-585.596 112.251,-581.089 116.936,-590.592 121.84,-585.596\"/>\r\n",
       "</g>\r\n",
       "<!-- 2440911606080 -->\r\n",
       "<g id=\"node14\" class=\"node\"><title>2440911606080</title>\r\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"184.5,-702 130.5,-702 130.5,-672 184.5,-672 184.5,-702\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"157.5\" y=\"-690\" font-family=\"monospace\" font-size=\"10.00\">b</text>\r\n",
       "<text text-anchor=\"middle\" x=\"157.5\" y=\"-679\" font-family=\"monospace\" font-size=\"10.00\"> (10)</text>\r\n",
       "</g>\r\n",
       "<!-- 2440911606080&#45;&gt;2440909505632 -->\r\n",
       "<g id=\"edge12\" class=\"edge\"><title>2440911606080&#45;&gt;2440909505632</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M157.5,-671.839C157.5,-664.214 157.5,-654.704 157.5,-646.45\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"161,-646.266 157.5,-636.266 154,-646.266 161,-646.266\"/>\r\n",
       "</g>\r\n",
       "<!-- 2441027545456&#45;&gt;2441027546944 -->\r\n",
       "<g id=\"edge13\" class=\"edge\"><title>2441027545456&#45;&gt;2441027546944</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M134.39,-506.748C129.218,-499.339 121.654,-488.504 115.306,-479.411\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"118.09,-477.285 109.496,-471.089 112.351,-481.292 118.09,-477.285\"/>\r\n",
       "</g>\r\n",
       "<!-- 2441027546080&#45;&gt;2441027545504 -->\r\n",
       "<g id=\"edge15\" class=\"edge\"><title>2441027546080&#45;&gt;2441027545504</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M134.39,-341.748C129.218,-334.339 121.654,-323.504 115.306,-314.411\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"118.09,-312.285 109.496,-306.089 112.351,-316.292 118.09,-312.285\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x23858946b50>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchviz\n",
    "torchviz.make_dot(loss, params=dict(W=model.W, b=model.b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This graph is what allows efficient implementation of the **back-propagation** algorithm which you'll learn about in the next lecture.\n",
    "\n",
    "By calling `.backward()` from the final loss tensor, pytorch automatically populated the `.grad` property of all leaves in this graph, without us having to explicitly specify them (`W` and `b`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The optimization will be as before, but now we'll take the gradients from the `grad` property of our parameter tensors.\n",
    "\n",
    "Therefore, the optimizer only needs access to the parameter tensors from the model.\n",
    "Later you'll see that `pytorch`'s `Optimizer` classes work in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:24.405910Z",
     "iopub.status.busy": "2022-03-31T05:57:24.405767Z",
     "iopub.status.idle": "2022-03-31T05:57:24.434454Z",
     "shell.execute_reply": "2022-03-31T05:57:24.434135Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "class SGDOptimizer:\n",
    "    \"\"\"\n",
    "    A simple gradient descent optimizer.\n",
    "    \"\"\"\n",
    "    def __init__(self, params: Sequence[Tensor], learn_rate: float):\n",
    "        self._params = params\n",
    "        self._learn_rate = learn_rate\n",
    "    \n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        Updates parameters in-place based on their gradients.\n",
    "        \"\"\"\n",
    "        with torch.autograd.no_grad(): # Don't track this operation\n",
    "            for param in self._params:\n",
    "                if param.grad is not None:\n",
    "                    param -= self._learn_rate * param.grad\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        \"\"\"\n",
    "        Zeros the parameters' gradients if they exist.\n",
    "        \"\"\"\n",
    "        for param in self._params:\n",
    "            if param.grad is not None:\n",
    "                param.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Inference and prediction accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:24.436398Z",
     "iopub.status.busy": "2022-03-31T05:57:24.436289Z",
     "iopub.status.idle": "2022-03-31T05:57:24.865375Z",
     "shell.execute_reply": "2022-03-31T05:57:24.865010Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy pre-training: 14.26%\n"
     ]
    }
   ],
   "source": [
    "def evaluate_accuracy(dataloader, model, max_batches=None):\n",
    "    n_correct = 0.\n",
    "    n_total = 0.\n",
    "    for i, (X, y) in enumerate(dataloader):\n",
    "        X = X.reshape(-1, n_features) # flatten images into vectors\n",
    "        \n",
    "        # Forward pass\n",
    "        with torch.autograd.no_grad():\n",
    "            y_hat = model(X)\n",
    "        \n",
    "        predictions = torch.argmax(y_hat, dim=1)\n",
    "        n_correct += torch.sum(predictions == y).type(torch.float32)\n",
    "        n_total += X.shape[0]\n",
    "        \n",
    "        if max_batches and i+1 >= max_batches:\n",
    "            break\n",
    "        \n",
    "    return (n_correct / n_total).item()\n",
    "\n",
    "test_set_acc = evaluate_accuracy(dl_test, MCLogisticRegression(n_features, n_classes))\n",
    "print(f'Test set accuracy pre-training: {test_set_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### The training loop\n",
    "\n",
    "This is a crucial part of any ML pipeline where model parameters get updated iteratively.\n",
    "\n",
    "One pass over the entire training data is called an **epoch**.\n",
    "When using `pytorch`, your training loop will generally contain the following steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Each epoch:\n",
    "    - Split training data into batches\n",
    "    - For each batch\n",
    "        - Forward pass: Compute predictions and build computation graph\n",
    "        - Calculate loss\n",
    "        - Set existing gradients to zero\n",
    "        - Backward pass: Use back-propagation algorithm to calculate the gradients\n",
    "        - Optimization step: Use the gradients to update the parameters\n",
    "    - Evaluate accuracy on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:24.867454Z",
     "iopub.status.busy": "2022-03-31T05:57:24.867240Z",
     "iopub.status.idle": "2022-03-31T05:57:24.889412Z",
     "shell.execute_reply": "2022-03-31T05:57:24.889080Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Define some training hyper-parameters\n",
    "epochs = 10\n",
    "max_batches = 50  # limit batches so training is fast (just as a demo)\n",
    "learn_rate = .005\n",
    "num_samples = len(ds_train)\n",
    "\n",
    "# Instantiate the model we'll train\n",
    "model = MCLogisticRegression(n_features, n_classes)\n",
    "\n",
    "# Instantiate the optimizer with model's parameters\n",
    "optimizer = SGDOptimizer(model.params, learn_rate=learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:24.891427Z",
     "iopub.status.busy": "2022-03-31T05:57:24.891315Z",
     "iopub.status.idle": "2022-03-31T05:57:32.282770Z",
     "shell.execute_reply": "2022-03-31T05:57:32.282443Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Avg Loss: 0.355, Train Acc: 44.44, Test Acc: 46.42\n",
      "Epoch 1. Avg Loss: 0.171, Train Acc: 61.75, Test Acc: 61.59\n",
      "Epoch 2. Avg Loss: 0.099, Train Acc: 68.78, Test Acc: 69.45\n",
      "Epoch 3. Avg Loss: 0.080, Train Acc: 74.06, Test Acc: 74.76\n",
      "Epoch 4. Avg Loss: 0.071, Train Acc: 78.56, Test Acc: 78.16\n",
      "Epoch 5. Avg Loss: 0.059, Train Acc: 79.47, Test Acc: 79.83\n",
      "Epoch 6. Avg Loss: 0.054, Train Acc: 80.19, Test Acc: 81.16\n",
      "Epoch 7. Avg Loss: 0.044, Train Acc: 81.97, Test Acc: 82.21\n",
      "Epoch 8. Avg Loss: 0.049, Train Acc: 81.25, Test Acc: 82.44\n",
      "Epoch 9. Avg Loss: 0.045, Train Acc: 82.75, Test Acc: 83.23\n"
     ]
    }
   ],
   "source": [
    "# Epoch: traverse all samples\n",
    "for e in range(epochs):\n",
    "    cumulative_loss = 0\n",
    "\n",
    "    # Loop over randdom batches of training data\n",
    "    for i, (X, y) in enumerate(dl_train):\n",
    "        \n",
    "        X = X.reshape(-1, n_features)\n",
    "        y_onehot = onehot(y, n_classes)\n",
    "        \n",
    "        # Forward pass: predictions and loss\n",
    "        y_hat = model(X)\n",
    "        loss = cross_entropy_loss(y_onehot, y_hat)\n",
    "        \n",
    "        # Clear previous gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Backward pass: calculate gradients \n",
    "        loss.backward() \n",
    "        \n",
    "        # Update model using the calculated gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        cumulative_loss += loss.item()\n",
    "        if i+1 > max_batches:\n",
    "            break\n",
    "\n",
    "    # Evaluation\n",
    "    test_accuracy = evaluate_accuracy(dl_test, model, max_batches)\n",
    "    train_accuracy = evaluate_accuracy(dl_train, model, max_batches)\n",
    "    \n",
    "    avg_loss = cumulative_loss/num_samples\n",
    "    print(f\"Epoch {e}. Avg Loss: {avg_loss:.3f}, Train Acc: {train_accuracy*100:.2f}, Test Acc: {test_accuracy*100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Final notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This is a very naive implementation, for example because\n",
    "    - We didn't treat the images properly.\n",
    "    - We didn't include any regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- PyTorch provides many functions and classes that we could have used, for example:\n",
    "  - Fully connected layer with model parameters\n",
    "  - Softmax\n",
    "  - SGD and many other optimizers\n",
    "  - Cross entropy loss\n",
    "  \n",
    "  however the purpose here was to show an (almost) from-scratch implementation using only tensors,\n",
    "  in order to see whats \"under the hood\" (more or less) of the PyTorch functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Thanks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**Credits**\n",
    "\n",
    "This tutorial was written by [Aviv A. Rosenberg](https://avivr.net).<br>\n",
    "To re-use, please provide attribution and link to the original.\n",
    "\n",
    "Some images in this tutorial were taken and/or adapted from the following sources:\n",
    "\n",
    "- MartinThoma [CC0], via Wikimedia Commons https://commons.wikimedia.org/wiki/File:Perceptron-unit.svg\n",
    "- Dr. Nadav Cohen, http://www.cohennadav.com/files/icermw19_slides.pdf\n",
    "- Fundamentals of Deep Learning, Nikhil Buduma, Oreilly 2017"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
